logging:
  base_folder: demo/buddi/training/
  run: demo_buddi_v02
  checkpoint_folder: '' 
  validation_folder: ''
datasets:
  train_names: ['behave']
  train_composition: [1.0]
  val_names: ['behave']
  behave:
    data_folder: /home/shubhikg/intercap
    pseudogt_folder: gt
    bev_folder: bev_process
  augmentation:
    use: false
  processing:
    use: false
    load_image: false
model:
  optimization:
    type: 'hhcs'
    print_loss: True
    render_iters: True
    use_diffusion: True
    use_gt_contact_map: False
    pretrained_diffusion_model_cfg: 'essentials/buddi/buddi_cond_bev_checkpoint_config.yaml'
    pretrained_diffusion_model_ckpt: 'essentials/buddi/buddi_cond_bev_checkpoint.pt'
    sds_type: 'fixed' # fixed, range or adaptive selection of noise level in SDS
    sds_t_fixed: 1
    sds_t_range: [25, 75]
    sds_t_adaptive_i: [1.0, 0.8, 0.6, 0.4, 0.2]
    sds_t_adaptive_t: [100, 80, 60, 40, 20]    
    hhcs:
      max_iters: [10, 100]
      num_prev_steps: 20
      slope_tol: -0.0001
    optimizer: 
      type: 'adam'
      adam:
        lr: 0.01
    losses:
      keypoint2d: # 2d keypoint loss 
        type: 'l2'
        squared: True
        weighted: True
        weight: [0.02, 0.02]
      init_pose: # penalize deviation from inital bev pose
        type: 'l2'
        squared: True
        d1_aggregation: 'none'
        weight: [200.0, 200.0]
      obj_reproj2D: # 2D object reprojection loss
        type: 'iou'
        weighted: True
        weight: [1000.0, 1000.0]
      diffusion_prior_orient: # sds loss
        type: 'l2'
        weight: [0.0, 0.0]
      diffusion_prior_pose: # sds loss
        type: 'l2'
        weight: [0.0, 0.0] #[100.0, 100.0]
      diffusion_prior_orient_obj: # sds loss
        type: 'l2'
        weight: [0.0, 0.0] #[100.0, 100.0]
      diffusion_prior_shape: # sds loss
        type: 'l2'
        weight: [0.0, 0.0] #[10.0, 0.0]
      diffusion_prior_rel_transl: # sds loss
        type: 'l2'
        weight: [1000.0, 1000.0] # [10000.0, 10000.0]
body_model:
  type: smplh
  smpl_family_folder: essentials/body_models # smplx original weights
  smplh:
    num_vertices: 6890
    init:
      batch_size: 1
      gender: male
      age: adult
      # kid_template_path: essentials/body_models/smil/smplx_kid_template.npy
      joint_mapper:
        use: true
        type: smpl_to_openpose
        smpl_to_openpose:
          use_hands: false
          use_face: false
          use_face_contour: false
          openpose_format: coco25
camera:
  type: 'perspective'
  perspective:
    afov_horizontal: 60 # inital angular field of view compatible with bev output
    roll: 180 # inital camera roll compatible with bev output
evaluation:
  metrics: ['v2v', 'mpjpe', 'pa_mpjpe', 'pairwise_pa_chamfer']